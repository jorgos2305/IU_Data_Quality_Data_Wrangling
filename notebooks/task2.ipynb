{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1099f61-e70f-4939-83f7-af9cc0a3fed8",
   "metadata": {},
   "source": [
    "# Data Quality and Data Wrangling \n",
    "## Course Code: DLBDSDQDW01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bc8316-7198-415b-aeea-78849b4f7e9a",
   "metadata": {},
   "source": [
    "## Task 2: Scrape the web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a41436-7851-4d39-929f-fa79c948859c",
   "metadata": {},
   "source": [
    "This notebook describes the implementation of Task 2 of the Data Quality and Data Wrangling course (DLBDSDQDW01), it contains the code use for experimentation and the creation of the visualization according to the requirements in the task description."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36800db-9cb6-4bb1-925d-6d15b136cc99",
   "metadata": {},
   "source": [
    "### Data sources\n",
    "The data was collected from the following sources:\n",
    "\n",
    "1. [OpenWeather](https://openweathermap.org/api/one-call-3#concept): for weather data such as temperature, humidity, pressure, etc.\n",
    "2. [AlphaVantage](https://www.alphavantage.co/documentation/): for Stock market data\n",
    "2. [USGS Earthquake](https://earthquake.usgs.gov/fdsnws/event/1/): earthquake data for the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb07882-e3b7-48da-ad2a-226265cca545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used packages\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import re\n",
    "import time\n",
    "import folium\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from datetime import date, datetime, timezone, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67cd3a-bdae-48d2-9de0-cfe1b096aaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API keys\n",
    "load_dotenv(Path().cwd().parent.joinpath(r\"config/.env\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ff84c6-03ad-45f4-b768-9dbd85c567b6",
   "metadata": {},
   "source": [
    "# Define location for time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15188c08-c23e-4860-b65b-c5f9fc6ef9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [\"Berlin\" , \"Munich\", \"Hamburg\", \"Baden-Baden\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d61bbd-55c4-488a-a4a3-882bb8bc362a",
   "metadata": {},
   "source": [
    "# Weather data\n",
    "\n",
    "Since the API provides data only for one timestamp and not the summary for the whole day, the request will be run every 2 hours, to get 12 readings per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8871f0-c12a-408e-aa3a-b45b833f0cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENWEATHER_API_KEY = os.getenv(\"OPENWEATHER_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9944ed6e-6bdd-4dfb-86d3-fbe2fb8269a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(url, headers:dict=None, params:dict=None):\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc264940-bd63-4281-8738-b20c891416eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geocoding endpoint - to get coordinates of the cities\n",
    "url_geocoding = \"http://api.openweathermap.org/geo/1.0/direct?\"\n",
    "params_geocoding = {\"q\":None, \"limit\":1, \"appid\" : OPENWEATHER_API_KEY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa58bf-fae0-4b87-8b79-b955dfd3aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_cities = []\n",
    "for city in cities:\n",
    "    params_geocoding[\"q\"] = city\n",
    "    response = fetch(url_geocoding, params=params_geocoding)\n",
    "    responses_cities.append(response)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a01265-ef2e-4cce-b3bf-8c1e6090dc4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "responses_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea5f4e-ae1c-4be9-9bbc-09d5a093983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_coordinates = {\"city\" : [], \"country\" : [], \"lon\" : [], \"lat\" : []}\n",
    "for response_list in responses_cities: # a response list is the response of the API, a list containing a dictionary\n",
    "    for response in response_list: # response is the dictionary containing the information of the countries\n",
    "        city_coordinates[\"city\"].append(response[\"name\"])\n",
    "        city_coordinates[\"lon\"].append(response[\"lon\"]) # X\n",
    "        city_coordinates[\"lat\"].append(response[\"lat\"]) # Y\n",
    "        city_coordinates[\"country\"].append(response[\"country\"])\n",
    "df_geolocations = pd.DataFrame(city_coordinates)\n",
    "df_geolocations[\"geometry\"] = df_geolocations.apply(lambda row: Point(row[\"lon\"], row[\"lat\"]), axis=1)\n",
    "df_geolocations = gpd.GeoDataFrame(df_geolocations, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "df_geolocations.to_csv(\"geocoding_openweather.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ff836-ba80-49b0-bb7d-409c684b5849",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geolocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd83a6a-6257-4a04-9a50-8dd31bd09fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geolocations.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7ea29-1b29-44f5-929f-61af75e177ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather endpoint - to get weather of the locations\n",
    "url_weather = \"https://pro.openweathermap.org/data/2.5/weather\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd56c4-a908-491f-845e-7da8ab86ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time zone for Berlin\n",
    "berlin = ZoneInfo(\"Europe/Berlin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c871595-6b91-43ea-ab70-d6f48c95bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now(berlin).replace(microsecond=0)\n",
    "\n",
    "responses_weather = []\n",
    "\n",
    "for nrow, record in df_geolocations.iterrows():\n",
    "    lon = record[\"lon\"]\n",
    "    lat = record[\"lat\"]\n",
    "    params = {\"units\":\"metric\",\n",
    "              \"lon\" : lon,\n",
    "              \"lat\" : lat,\n",
    "              \"date\" : today.isoformat(),\n",
    "              \"appid\" : OPENWEATHER_API_KEY}\n",
    "    response = requests.get(url_weather, params)\n",
    "    response.raise_for_status()\n",
    "    responses_weather.append(response)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55bf07c-3632-409f-a856-4848cf9cacef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the response look like?\n",
    "responses_weather[0].json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88283f61-f779-429b-9352-dbad0b619133",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = {\"name\" : [], # city name - it might not match no automatic geocoding by the API\n",
    "           \"temperature\" : [], # Temperature\n",
    "           \"temperature_max\" : [], # Max temp at the moment\n",
    "           \"temperature_min\" : [], # Min temp at the moment\n",
    "           \"feels_like\" : [], # Human perception of the weather\n",
    "           \"humidity\":[], #\n",
    "           \"wind_speed\":[], # in m/\n",
    "           \"wind_direction\" : [],\n",
    "           \"description\":[],\n",
    "           \"timestamp\":[]}\n",
    "\n",
    "for response in responses_weather:\n",
    "    weather_data = response.json()\n",
    "    weather[\"name\"].append(weather_data[\"name\"])\n",
    "    weather[\"temperature\"].append(weather_data[\"main\"][\"temp\"])\n",
    "    weather[\"temperature_max\"].append(weather_data[\"main\"][\"temp_max\"])\n",
    "    weather[\"temperature_min\"].append(weather_data[\"main\"][\"temp_min\"])\n",
    "    weather[\"feels_like\"].append(weather_data[\"main\"][\"feels_like\"])\n",
    "    weather[\"humidity\"].append(weather_data[\"main\"][\"humidity\"])\n",
    "    weather[\"wind_speed\"].append(weather_data[\"wind\"][\"speed\"])\n",
    "    weather[\"wind_direction\"].append(weather_data[\"wind\"][\"deg\"])\n",
    "    weather[\"description\"].append(weather_data[\"weather\"][0][\"description\"])\n",
    "    weather[\"timestamp\"].append(datetime.fromtimestamp(weather_data[\"dt\"]))\n",
    "    \n",
    "df_weather = pd.DataFrame(weather)\n",
    "df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eebd147-065d-4655-ab9f-a484fc6c82fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commbine into one dataframe for the weather data\n",
    "df_weather = pd.concat([df_geolocations, df_weather], axis=1)\n",
    "df_weather = df_weather.drop(\"name\", axis=1)\n",
    "df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4398a-0e51-4bc3-92b2-8a52357f707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10edd32-f23e-4934-861f-d123a4b9f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if weather data exists load it, if not\n",
    "if Path(\"weather_data.csv\").exists():\n",
    "    print(\"loading latest data\")\n",
    "    history_df = pd.read_csv(\"weather_data.csv\")\n",
    "    # this dataframe is the final weather data. Store in staging area to combine later with further data\n",
    "    df_weather = pd.concat([history_df, df_weather], axis=0).sort_values(by=[\"city\", \"timestamp\"], ascending=False)\n",
    "    df_weather.to_csv(\"weather_data.csv\", index=False)\n",
    "else:\n",
    "    print(\"weather_data.csv does not exist. Latest data will be stored\")\n",
    "    df_weather.to_csv(\"weather_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3f76a5-790d-4f02-9e6a-605052110988",
   "metadata": {},
   "source": [
    "# Stock market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8863c11c-8ab4-4659-b376-b6d6af9e600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHAVANTAGE_API_KEY = os.getenv(\"ALPHAVANTAGE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7abf9a-f3c8-4306-9c01-5a9b12b34dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = (\"NVDA\",\"AAPL\",\"META\",\"RHM.DE\",\"SPY\",\"URTH\",\"ACWI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe154ba-5afb-4208-a3c8-40e0b9b7cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock_market = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dc4571-9bcc-4b21-94b0-28c7eea59b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_stocks = \"https://www.alphavantage.co/query\"\n",
    "for ticker in tickers:\n",
    "    params_stocks = {\"function\" : \"TIME_SERIES_DAILY\", # this endpoint provides a daily time series of the equity specified\n",
    "                     \"symbol\" : ticker, # the equity -> replace this by all the companies that should be followed\n",
    "                     \"outputsize\" : \"compact\",\n",
    "                     \"dataype\" : \"json\",\n",
    "                     \"apikey\" : ALPHAVANTAGE_API_KEY}\n",
    "    response = requests.get(url_stocks, params=params_stocks)\n",
    "    response.raise_for_status()\n",
    "    stocks = response.json()\n",
    "    df = pd.DataFrame(stocks[\"Time Series (Daily)\"]).T\n",
    "    df.index = pd.to_datetime(df.index, dayfirst=False)\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    df = df.rename(columns={\"1. open\" :\"open\", \"2. high\":\"high\", \"3. low\":\"low\", \"4. close\":\"close\", \"5. volume\": \"volume\"})\n",
    "    df_stock_market[ticker] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d92e39-0fc4-4c2a-bb23-8a242ea64389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock_market.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00864e8-47c2-4a32-84f9-616e6580df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in df_stock_market:\n",
    "    print(ticker)\n",
    "    print(df_stock_market[ticker].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6724ca8e-5d23-4cc2-a5cd-d9d0e9844f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in df_stock_market:\n",
    "    display(df_stock_market[ticker].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb1033c-2d09-479f-916c-0b528c61d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24,24), nrows=len(tickers), ncols=1, sharex=True)\n",
    "for idx, ticker in enumerate(tickers):\n",
    "    df = df_stock_market[ticker]\n",
    "    ax[idx].set_title(ticker)\n",
    "    ax[idx].plot(df[\"open\"], marker='.', label=\"Open\")\n",
    "    ax[idx].plot(df[\"close\"], marker='.', label=\"Close\")\n",
    "    #ax[idx].set_ylim([0,250])\n",
    "    ax[idx].grid(True, axis=\"y\", linestyle=\":\", linewidth=0.5)\n",
    "    ax[idx].spines[[\"top\", \"right\", \"bottom\", \"left\"]].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7f4ef-7a3d-431e-96d1-8c6a4c3becb4",
   "metadata": {},
   "source": [
    "# Earthquake data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fd89f0-a851-450a-b833-a00c5c175058",
   "metadata": {},
   "source": [
    "Parameters according the API documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8572ee65-725d-414a-b8cc-ea9f573261b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL\n",
    "url = r\"https://earthquake.usgs.gov/fdsnws/event/1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb3559c-62e4-49cc-9535-9bb9bf599b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to the API documentation all times use UTC\n",
    "# Time in Germany should be specified when making a request\n",
    "berlin = ZoneInfo(\"Europe/Berlin\")\n",
    "tokyo = ZoneInfo(\"Asia/Tokyo\")\n",
    "now = datetime.now(tokyo).replace(microsecond=0)\n",
    "yesterday = now - timedelta(days=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c710a99c-7462-4a30-a117-77b4f6997b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query parameters\n",
    "params = {\"method\" : \"query\", # submit a data request\n",
    "          \"format\" : \"geojson\", # reponse format\n",
    "          \"minlatitude\" : 24.0, # Get earthquakes in Japan\n",
    "          \"maxlatitude\" : 46.0,\n",
    "          \"minlongitude\" : 122.0,\n",
    "          \"maxlongitude\" : 146,\n",
    "          \"limit\" : 100, # Limit results to this value\n",
    "          \"starttime\": yesterday.isoformat(), # the API expect ISO time format, here it is set\n",
    "          \"endtime\" : now.isoformat(),\n",
    "          \"orderby\" : \"time\"} # sort the results from most recent to oldest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a871ed3-d0ce-4c7a-bafc-49798c7ea466",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[40,140], zoom_start=5)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee58d06-cfe6-4f90-9d4a-49ba7121c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data from the API\n",
    "response = requests.get(url, params=params)\n",
    "earthquakes = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f6d712-aad6-48e8-91b2-551155a89977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same names of the reponse in the dict for easier iteration\n",
    "records = {\"time\":[], # time when the event ocurred - in milliseconds since the epoch\n",
    "           \"mag\":[], # magnitude of the event - combine with magType for interpretation\n",
    "           \"magType\":[], # magnitude types are described in the API documentation - must be mapped to a name easier to understand\n",
    "           \"alert\":[],\n",
    "           \"tsunami\":[],\n",
    "           \"place\":[],\n",
    "           \"coordinates\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c48de4-82f0-4c62-8897-ac7c77c6c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for earthquake in earthquakes[\"features\"]:\n",
    "    for feature in records:\n",
    "        if feature in earthquake[\"properties\"]:\n",
    "            records[feature].append(earthquake[\"properties\"][feature])\n",
    "        else:\n",
    "            records[feature].append(earthquake[\"geometry\"][feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d009e0d-d3a8-4f50-8d60-306a42ad3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_type_description = {\n",
    "    \"Mw\": \"Moment Magnitude\",\n",
    "    \"Ms\": \"Surface Wave Magnitude\",\n",
    "    \"Mb\": \"Body Wave Magnitude\",\n",
    "    \"ML\": \"Local (Richter) Magnitude\",\n",
    "    \"mB\": \"Broad-band Body Wave Magnitude\",\n",
    "    \"Mb_Lg\": \"Lg-Wave Magnitude\",\n",
    "    \"MD\": \"Duration Magnitude\",\n",
    "    \"MH\": \"Hand-calculated Magnitude\",\n",
    "    \"MI\": \"Intensity-derived Magnitude\",\n",
    "    \"Me\": \"Energy Magnitude\",\n",
    "    \"Mg\": \"Surface Wave from Ground Displacement\",\n",
    "    \"MWb\": \"Moment Magnitude from Body Waves\",\n",
    "    \"Mwr\": \"Regional Moment Magnitude\",\n",
    "    \"MwC\": \"Centroid Moment Magnitude\",\n",
    "    \"MwB\": \"Body-wave Derived Moment Magnitude\",\n",
    "    \"mww\": \"Moment Magnitude from W-phase\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5606fe59-2431-47ef-8991-6c6692c0d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: set alert to black in case no alert\n",
    "df = pd.DataFrame(records)\n",
    "df[\"geometry\"] = df.coordinates.apply(lambda coord: Point(coord[:2]))\n",
    "df[\"depth\"] = df.coordinates.apply(lambda coord: coord[-1])\n",
    "df = df.drop(\"coordinates\", axis=1)\n",
    "df = df.rename(columns={\"time\":\"timestamp\", \"mag\":\"magnitude\", \"magType\":\"scale\"})\n",
    "df = df.replace(mag_type_description)\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de07189-b180-43b4-b020-06f3ff028dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168ff89-3a51-4fad-bce1-9baf3459de1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "geodf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bc5ae8-b077-4364-9d24-59a7c8ec4da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0662b078-43a2-47ab-82ff-ff541d0f7dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
